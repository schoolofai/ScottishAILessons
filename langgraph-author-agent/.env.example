# API Keys Configuration
# Copy this file to .env and fill in your actual API keys

# ═══════════════════════════════════════════════════════════════
# AI Model Configuration for Lesson Authoring
# ═══════════════════════════════════════════════════════════════

# LESSON_MODEL_VERSION - Select which AI model to use for lesson generation
#
# ⚠️  CRITICAL: Model MUST support tool calling (function calling) for DeepAgents!
#
# Cloud Models (Paid, API Key Required):
#   - gemini-2.5-pro      : High-quality Gemini (default, requires GOOGLE_API_KEY)
#   - gemini-flash-lite   : Fast, cost-effective Gemini (requires GOOGLE_API_KEY)
#
# Local Models via Ollama (Free, Tool Calling Verified):
#   - llama-4-scout       : Meta Llama 4 Scout (67GB, MoE, 10M context) - RECOMMENDED!
#   - llama-3.3-70b       : Meta Llama 3.3 70B (previous gen, stable)
#   - llama-3.1-70b       : Meta Llama 3.1 70B (proven tool calling)
#   - qwen-2.5-72b        : Alibaba Qwen2.5 72B (strong reasoning)
#   - llama-3.1-8b        : Meta Llama 3.1 8B (budget, faster)
#   - mixtral-8x22b       : Mistral Mixtral 8x22B (MoE architecture)
#   - command-r-plus      : Cohere Command-R Plus (RAG-optimized)
#
# Setup Ollama models:
#   1. Install Ollama: https://ollama.com/download
#   2. Start Ollama: ollama serve
#   3. Pull Llama 4: ollama pull llama4  (67GB download, ~1-2 hours)
#
# Context Window Configuration (Automatic):
# Ollama models are pre-configured with optimized context windows:
#   - Llama 4 Scout / Llama 3.3 70B: 64K tokens (complex lesson authoring)
#   - Llama 3.1 70B / Mixtral / Command-R+: 32K tokens (balanced)
#   - Llama 3.1 8B: 16K tokens (memory-conscious)
#   - Qwen 2.5 72B: 64K tokens (strong reasoning)
#
# Memory Impact (Mac Pro Max 128GB, using Llama 4 Scout example):
#   - Base model: 67GB
#   - 64K context: +5-6GB
#   - Total: ~85-90GB (43GB free, excellent headroom)
#   - Inference speed: ~15-20 tokens/sec (10-15% slower than 2K default)
#
# To adjust context window, edit num_ctx in src/model_factory.py
# Common sizes: 16384 (16K), 32768 (32K), 65536 (64K), 131072 (128K)
#
# IMPORTANT: Restart the LangGraph server after changing this value
LESSON_MODEL_VERSION=gemini-2.5-pro

# ═══════════════════════════════════════════════════════════════
# API Keys for Cloud AI Providers
# ═══════════════════════════════════════════════════════════════

# Google API Key for Gemini models
# Get your key at: https://aistudio.google.com/app/apikey
# Required for: gemini-2.5-pro, gemini-flash-lite
GOOGLE_API_KEY=your_google_api_key_here

# Tavily API Key for web search
# Get your key at: https://tavily.com/
TAVILY_API_KEY=your_tavily_api_key_here

# Anthropic API Key for Claude LLM
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Optional: LangSmith for tracing (helpful for debugging)
# Get your key at: https://smith.langchain.com/
# LANGSMITH_API_KEY=your_langsmith_api_key_here
# LANGSMITH_TRACING=true
# LANGSMITH_PROJECT=langgraph-author-agent

# Appwrite MCP Integration (optional but recommended for SoW Author Agent)
# Required for accessing curriculum database with SQA education data
# Get credentials from: https://cloud.appwrite.io/console
APPWRITE_PROJECT_ID=your_project_id_here
APPWRITE_API_KEY=your_api_key_here
APPWRITE_ENDPOINT=https://cloud.appwrite.io/v1

# Available Appwrite databases:
# - sqa_education: Production SQA curriculum data and course structures
# - sqa_education_test: Testing/staging curriculum data
# - default: Scottish AI Lessons general data